{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from nmr_spectrum import NMRSpectrum\n",
    "from spectrum import Spectrum\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "components_names = [\"Pinene\", \"Benzyl benzoate\"]\n",
    "\n",
    "protons_list = [16, 12]\n",
    "\n",
    "filename = \"preprocessed_mix.csv\"\n",
    "mix = np.loadtxt(filename, delimiter=\",\")\n",
    "# If you are using file exported from Mnova, comment line above and uncomment line below.\n",
    "# mix = np.loadtxt(filename, delimiter='\\t', usecols=[0,1])\n",
    "\n",
    "how_many_components = len(components_names)\n",
    "names = [\"comp\" + str(i) for i in range(how_many_components)]\n",
    "\n",
    "files_with_components = [\"preprocessed_comp0.csv\", \"preprocessed_comp1.csv\"]\n",
    "spectra = []\n",
    "for i in range(how_many_components):\n",
    "    filename = files_with_components[i]\n",
    "    spectra.append(np.loadtxt(filename, delimiter=\",\"))\n",
    "    # If you are using file exported from Mnova, comment line above and uncomment line below.\n",
    "    # spectra.append(np.loadtxt(filename, delimiter='\\t', usecols=[0,1]))\n",
    "\n",
    "spectra2: List[NMRSpectrum] = []\n",
    "names = []\n",
    "for i in range(len(spectra)):\n",
    "    spectra2.append(\n",
    "        NMRSpectrum(\n",
    "            confs=list(zip(spectra[i][:, 0], spectra[i][:, 1])), protons=protons_list[i]\n",
    "        )\n",
    "    )\n",
    "    names.append(\"comp\" + str(i))\n",
    "\n",
    "spectra = spectra2\n",
    "del spectra2\n",
    "mix = NMRSpectrum(confs=list(zip(mix[:, 0], mix[:, 1])))\n",
    "mix.trim_negative_intensities()\n",
    "mix.normalize()\n",
    "for sp in spectra:\n",
    "    sp.trim_negative_intensities()\n",
    "    sp.normalize()\n",
    "plt.title(\"Mixture\")\n",
    "mix.plot(profile=True)\n",
    "\n",
    "def generate_synthetic_mixture(components, true_p):\n",
    "    \"\"\"Generate a synthetic mixture from components based on given proportions.\"\"\"\n",
    "    # Create mixture using ScalarProduct\n",
    "    synthetic_mix = Spectrum.ScalarProduct(components, true_p)\n",
    "    synthetic_mix.normalize()\n",
    "    return synthetic_mix\n",
    "\n",
    "p = 0.4 # 0.01 # 0.3\n",
    "# p = 0.5\n",
    "calculated_mix = generate_synthetic_mixture(spectra, [p, 1-p])\n",
    "calculated_mix.normalize()\n",
    "\n",
    "plt.title(f\"Synthetic Mixture [{p}, {1-p}]\")\n",
    "calculated_mix.plot(profile=True)\n",
    "\n",
    "for i, sp in enumerate(spectra):\n",
    "    plt.title(\"Component \" + str(i))\n",
    "    sp.plot(profile=True)\n",
    "print(spectra[0].confs[:10])\n",
    "\n",
    "\n",
    "# Użyć unbalanced optimal transport zamiast wassersteina z total variation karą\n",
    "\n",
    "# Flat metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import math\n",
    "\n",
    "\n",
    "def filter_significant_features(first, second, n_features):\n",
    "    \"\"\"\n",
    "    Select the n most significant features from both spectra.\n",
    "    Uses combined intensity to determine importance.\n",
    "    \"\"\"\n",
    "    # Create dictionary with combined intensities\n",
    "    combined_intensities = {}\n",
    "    for mz, prob in first.confs:\n",
    "        combined_intensities[mz] = combined_intensities.get(mz, 0) + prob\n",
    "    for mz, prob in second.confs:\n",
    "        combined_intensities[mz] = combined_intensities.get(mz, 0) + prob\n",
    "\n",
    "    # Select top n features\n",
    "    selected_features = set(\n",
    "        sorted(\n",
    "            combined_intensities.keys(),\n",
    "            key=lambda mz: combined_intensities[mz],\n",
    "            reverse=True,\n",
    "        )[:n_features]\n",
    "    )\n",
    "\n",
    "    # Filter spectra\n",
    "    filtered_first = first.copy()\n",
    "    filtered_first.confs = [\n",
    "        (mz, prob) for mz, prob in first.confs if mz in selected_features\n",
    "    ]\n",
    "\n",
    "    filtered_second = second.copy()\n",
    "    filtered_second.confs = [\n",
    "        (mz, prob) for mz, prob in second.confs if mz in selected_features\n",
    "    ]\n",
    "\n",
    "    # Re-normalize\n",
    "    filtered_first.normalize()\n",
    "    filtered_second.normalize()\n",
    "\n",
    "    return filtered_first, filtered_second\n",
    "\n",
    "\n",
    "def WSDistanceMoves(first, second):\n",
    "    \"\"\"Return the optimal transport plan between self and other.\"\"\"\n",
    "    try:\n",
    "        ii = 0\n",
    "        leftoverprob = second.confs[0][1]\n",
    "        for mass, prob in first.confs:\n",
    "            while leftoverprob <= prob:\n",
    "                yield (second.confs[ii][0], mass, leftoverprob)\n",
    "                prob -= leftoverprob\n",
    "                ii += 1\n",
    "                leftoverprob = second.confs[ii][1]\n",
    "            yield (second.confs[ii][0], mass, prob)\n",
    "            leftoverprob -= prob\n",
    "    except IndexError:\n",
    "        return\n",
    "\n",
    "\n",
    "def WSDistance(first, second, n_features=None):\n",
    "    \"\"\"\n",
    "    Compute Wasserstein distance using only n most significant features.\n",
    "    If n_features is None, use all features.\n",
    "    \"\"\"\n",
    "    if n_features is not None and n_features < len(first.confs) + len(second.confs):\n",
    "        first, second = filter_significant_features(first, second, n_features)\n",
    "\n",
    "    if not np.isclose(sum(x[1] for x in first.confs), 1.0):\n",
    "        raise ValueError(\"Self is not normalized.\")\n",
    "    if not np.isclose(sum(x[1] for x in second.confs), 1.0):\n",
    "        raise ValueError(\"Other is not normalized.\")\n",
    "\n",
    "    return math.fsum((x[0] - x[1]) * x[2] for x in WSDistanceMoves(first, second))\n",
    "\n",
    "\n",
    "def WSGradient(source, target, n_features=None, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Compute numerical gradient of WSDistance with respect to mz values of `source`\n",
    "    using only n most significant features.\n",
    "    \"\"\"\n",
    "    if n_features is not None and n_features < len(source.confs) + len(target.confs):\n",
    "        source, target = filter_significant_features(source, target, n_features)\n",
    "\n",
    "    source.normalize()\n",
    "    target.normalize()\n",
    "\n",
    "    mzs = np.array([mz for mz, inten in source.confs])\n",
    "    intensities = np.array([inten for mz, inten in source.confs])\n",
    "    grad = np.zeros(len(mzs))\n",
    "\n",
    "    for i in trange(len(mzs), desc=\"Computing WSDistance gradient\"):\n",
    "        mz_plus = mzs.copy()\n",
    "        mz_minus = mzs.copy()\n",
    "        mz_plus[i] += epsilon\n",
    "        mz_minus[i] -= epsilon\n",
    "\n",
    "        source_plus = Spectrum(confs=list(zip(mz_plus, intensities)))\n",
    "        source_minus = Spectrum(confs=list(zip(mz_minus, intensities)))\n",
    "\n",
    "        source_plus.normalize()\n",
    "        source_minus.normalize()\n",
    "\n",
    "        dist_plus = WSDistance(target, source_plus)\n",
    "        dist_minus = WSDistance(target, source_minus)\n",
    "\n",
    "        grad[i] = (dist_plus - dist_minus) / (2 * epsilon)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "# Use only n most significant features\n",
    "distance = WSDistance(spectra[0], spectra[1], n_features=2000)\n",
    "difference = WSDistance(spectra[0], spectra[1]) - distance\n",
    "print(difference)\n",
    "print(distance)\n",
    "\n",
    "# Compute gradient using only 20 most significant features\n",
    "gradient = WSGradient(spectra[0], spectra[1], n_features=1000)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_gradient(mix, comp0, comp1, p, epsilon=1e-5):\n",
    "    delta = epsilon\n",
    "\n",
    "    p_plus = np.array([p[0] + delta, p[1] - delta])\n",
    "    p_minus = np.array([p[0] - delta, p[1] + delta])\n",
    "\n",
    "    p_plus = np.clip(p_plus, 1e-6, 1)\n",
    "    p_plus /= p_plus.sum()\n",
    "\n",
    "    p_minus = np.clip(p_minus, 1e-6, 1)\n",
    "    p_minus /= p_minus.sum()\n",
    "\n",
    "    sp_plus = Spectrum.ScalarProduct([comp0, comp1], p_plus)\n",
    "    sp_minus = Spectrum.ScalarProduct([comp0, comp1], p_minus)\n",
    "\n",
    "    sp_plus.normalize()\n",
    "    sp_minus.normalize()\n",
    "\n",
    "    grad = (mix.WSDistance(sp_plus) - mix.WSDistance(sp_minus)) / (2 * epsilon)\n",
    "\n",
    "    # Gradient of p[1] is -grad because p[1] = 1 - p[0]\n",
    "    grad_vec = np.array([grad, -grad])\n",
    "\n",
    "    return grad_vec\n",
    "\n",
    "\n",
    "def mirror_descent_two_weights(\n",
    "    mix, comp0, comp1, learning_rate=1.0, T=100, epsilon=1e-5, lmd = 0.99\n",
    "):\n",
    "    p = np.array([0.5, 0.5])  # start from uniform mixture\n",
    "    history = [p.copy()]\n",
    "    scores = []\n",
    "\n",
    "    for _ in trange(T, desc=\"Mirror Descent (2 weights)\"):\n",
    "        # Track score (distance from current estimate to true mixture)\n",
    "        estimated_mix = Spectrum.ScalarProduct([comp0, comp1], p)\n",
    "        estimated_mix.normalize()\n",
    "        ws = mix.WSDistance(estimated_mix)\n",
    "        scores.append(ws)\n",
    "\n",
    "        # Compute gradient\n",
    "        grad_vec = calculate_gradient(mix, comp0, comp1, p, epsilon)\n",
    "\n",
    "        # Mirror descent update\n",
    "        w = p * np.exp(-learning_rate * grad_vec)\n",
    "        p = w / w.sum()\n",
    "        learning_rate *= lmd\n",
    "        history.append(p.copy())\n",
    "\n",
    "    return p, np.array(history), np.array(scores)\n",
    "\n",
    "\n",
    "# Run mirror descent\n",
    "mix.normalize()\n",
    "spectra[0].normalize()\n",
    "spectra[1].normalize()\n",
    "\n",
    "final_p, traj, score_history = mirror_descent_two_weights(\n",
    "    mix, spectra[0], spectra[1], learning_rate=0.0005, T=50\n",
    ")\n",
    "\n",
    "# Reconstruct mixture from estimated weights\n",
    "estimated_mix = Spectrum.ScalarProduct([spectra[0], spectra[1]], final_p)\n",
    "estimated_mix.normalize()\n",
    "\n",
    "# Compute Wasserstein distance to the actual mixture\n",
    "ws_dist = WSDistance(mix, estimated_mix)\n",
    "\n",
    "# Compute Wasserstein distance for the given mixture\n",
    "given_p = np.array([0.393072, 0.606928])\n",
    "given_mix = Spectrum.ScalarProduct([spectra[0], spectra[1]], given_p)\n",
    "given_mix.normalize()\n",
    "ws_dist_given = WSDistance(mix, given_mix)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal weights:\")\n",
    "print(f\"  comp1 = {final_p[0]:.4f}\")\n",
    "print(f\"  comp2 = {final_p[1]:.4f}\")\n",
    "print(f\"\\nFinal Wasserstein distance to true mixture: {ws_dist:.6f}\")\n",
    "print(\n",
    "    f\"\\nWasserstein distance for given mixture (0.393072, 0.606928): {ws_dist_given:.6f}\"\n",
    ")\n",
    "\n",
    "plt.plot(traj[:, 0], label=\"Component 0\")\n",
    "plt.plot(traj[:, 1], label=\"Component 1\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.title(\"Mirror Descent Weight Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(score_history, marker=\"o\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wasserstein Distance\")\n",
    "plt.title(\"Distance to True Mixture Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def proportions_test():\n",
    "    def test_mirror_descent(components, true_p, learning_rate=0.0005, T=100, epsilon=1e-5):\n",
    "        \"\"\"Test mirror descent algorithm on a synthetic mixture with known proportions.\"\"\"\n",
    "        # Generate synthetic mixture\n",
    "        synthetic_mix = generate_synthetic_mixture(components, true_p)\n",
    "        \n",
    "        # Run mirror descent to recover proportions\n",
    "        recovered_p, traj, score_history = mirror_descent_two_weights(\n",
    "            synthetic_mix, components[0], components[1], learning_rate=learning_rate, T=T, epsilon=epsilon\n",
    "        )\n",
    "        \n",
    "        # Calculate error between true and recovered proportions\n",
    "        error = np.linalg.norm(true_p - recovered_p)\n",
    "        \n",
    "        return recovered_p, traj, score_history, error\n",
    "\n",
    "    # List of proportion pairs to test\n",
    "    test_proportions = [\n",
    "        [0.2, 0.8],\n",
    "        [0.4, 0.6],\n",
    "        [0.9, 0.1]\n",
    "    ]\n",
    "\n",
    "    # Convert to numpy arrays and ensure they sum to 1\n",
    "    test_proportions = [np.array(p) / sum(p) for p in test_proportions]\n",
    "\n",
    "    # Run tests (without tqdm to avoid widget issues)\n",
    "    results = []\n",
    "    print(\"Testing proportions:\")\n",
    "    for i, true_p in enumerate(test_proportions):\n",
    "        print(f\"  Testing {i+1}/{len(test_proportions)}: p={true_p}\")\n",
    "        recovered_p, traj, score_history, error = test_mirror_descent(\n",
    "            spectra, true_p, learning_rate=0.015, T=30\n",
    "        )\n",
    "        results.append({\n",
    "            \"true_p\": true_p,\n",
    "            \"recovered_p\": recovered_p,\n",
    "            \"traj\": traj,\n",
    "            \"score_history\": score_history,\n",
    "            \"error\": error\n",
    "        })\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nTest Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'True Proportions':<25} {'Recovered Proportions':<25} {'Error':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for res in results:\n",
    "        true_str = f\"[{res['true_p'][0]:.3f}, {res['true_p'][1]:.3f}]\"\n",
    "        recovered_str = f\"[{res['recovered_p'][0]:.3f}, {res['recovered_p'][1]:.3f}]\"\n",
    "        print(f\"{true_str:<25} {recovered_str:<25} {res['error']:.6f}\")\n",
    "\n",
    "    # Visualization of proportions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    true_props = np.array([res['true_p'][0] for res in results])\n",
    "    recovered_props = np.array([res['recovered_p'][0] for res in results])\n",
    "    plt.scatter(true_props, recovered_props)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlabel('True proportion of component 0')\n",
    "    plt.ylabel('Recovered proportion of component 0')\n",
    "    plt.title('True vs Recovered Proportions')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot errors\n",
    "    plt.subplot(1, 2, 2)\n",
    "    errors = [res['error'] for res in results]\n",
    "    plt.bar(range(len(errors)), errors)\n",
    "    plt.xticks(range(len(errors)), [f\"[{p[0]:.1f}, {p[1]:.1f}]\" for p in test_proportions])\n",
    "    plt.xlabel('True proportions')\n",
    "    plt.ylabel('L2 Error')\n",
    "    plt.title('Proportion Recovery Error')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot convergence for each test case\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, res in enumerate(results):\n",
    "        plt.subplot(len(results), 2, 2*i+1)\n",
    "        plt.plot(res['traj'][:, 0], label='Comp 0')\n",
    "        plt.plot(res['traj'][:, 1], label='Comp 1')\n",
    "        plt.axhline(res['true_p'][0], color='r', linestyle='--', alpha=0.5, label='True comp 0')\n",
    "        plt.axhline(res['true_p'][1], color='g', linestyle='--', alpha=0.5, label='True comp 1')\n",
    "        plt.title(f\"Proportion Convergence for p={res['true_p']}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(len(results), 2, 2*i+2)\n",
    "        plt.plot(res['score_history'])\n",
    "        plt.title(f\"Wasserstein Distance for p={res['true_p']}\")\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "kappa_mixture = 0.25\n",
    "kappa_components = 0.22\n",
    "\n",
    "\n",
    "def transport_cost_conf(conf, target):\n",
    "    source_mz, source_intensity = conf\n",
    "    remaining = source_intensity\n",
    "    cost = 0.0\n",
    "    target_confs = [(mz, inten) for mz, inten in target.confs]\n",
    "\n",
    "    lo, hi = 0, len(target_confs)\n",
    "    while lo < hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        if target_confs[mid][0] < source_mz:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            hi = mid\n",
    "    idx = lo\n",
    "    left = idx - 1\n",
    "    right = idx\n",
    "\n",
    "    while remaining > 0 and (left >= 0 or right < len(target_confs)):\n",
    "        left_dist = (\n",
    "            abs(source_mz - target_confs[left][0]) if left >= 0 else float(\"inf\")\n",
    "        )\n",
    "        right_dist = (\n",
    "            abs(source_mz - target_confs[right][0])\n",
    "            if right < len(target_confs)\n",
    "            else float(\"inf\")\n",
    "        )\n",
    "        if left_dist <= right_dist:\n",
    "            assigned = min(remaining, target_confs[left][1])\n",
    "            cost += left_dist * assigned\n",
    "            remaining -= assigned\n",
    "            new_val = target_confs[left][1] - assigned\n",
    "            target_confs[left] = (target_confs[left][0], new_val)\n",
    "            if new_val <= 1e-12:\n",
    "                left -= 1\n",
    "        else:\n",
    "            assigned = min(remaining, target_confs[right][1])\n",
    "            cost += right_dist * assigned\n",
    "            remaining -= assigned\n",
    "            new_val = target_confs[right][1] - assigned\n",
    "            target_confs[right] = (target_confs[right][0], new_val)\n",
    "            if new_val <= 1e-12:\n",
    "                right += 1\n",
    "    return cost\n",
    "\n",
    "\n",
    "def calculate_zeta_and_omega(\n",
    "    mix: NMRSpectrum,\n",
    "    components: List[NMRSpectrum],\n",
    "    kappa_mixture=kappa_mixture,\n",
    "    kappa_components=kappa_components,\n",
    "):\n",
    "    logger.info(\"Starting calculation of zeta and omega.\")\n",
    "    uniform_weights = np.ones(len(components)) / len(components)\n",
    "    combined_components = Spectrum.ScalarProduct(components, uniform_weights)\n",
    "    combined_components.normalize()\n",
    "\n",
    "    final_zeta = []\n",
    "    final_omega = []\n",
    "\n",
    "    for mz, intensity in tqdm(mix.confs, desc=\"Processing mix confs\"):\n",
    "        if intensity < 1e-5:\n",
    "            continue\n",
    "        ws_distance = transport_cost_conf((mz, intensity), combined_components)\n",
    "        normalized_distance = ws_distance / intensity if intensity > 0 else 0\n",
    "      \n",
    "        if normalized_distance > 1e-3:\n",
    "            weight = normalized_distance - kappa_mixture\n",
    "            final_zeta.append((mz, intensity * weight))\n",
    "\n",
    "    for mz, intensity in tqdm(combined_components.confs, desc=\"Processing combined components confs\"):\n",
    "        ws_distance = transport_cost_conf((mz, intensity), mix)\n",
    "        normalized_distance = ws_distance / intensity if intensity > 0 else 0\n",
    "       \n",
    "        if normalized_distance > 1e-3:\n",
    "            weight = normalized_distance - kappa_components\n",
    "            final_omega.append((mz, intensity * weight))\n",
    "\n",
    "    final_zeta_spectrum = (\n",
    "        Spectrum(confs=final_zeta) if final_zeta else Spectrum(confs=[])\n",
    "    )\n",
    "    final_omega_spectrum = (\n",
    "        Spectrum(confs=final_omega) if final_omega else Spectrum(confs=[])\n",
    "    )\n",
    "\n",
    "    if final_zeta:\n",
    "        final_zeta_spectrum.normalize()\n",
    "    if final_omega:\n",
    "        final_omega_spectrum.normalize()\n",
    "\n",
    "    logger.info(\"Zeta and omega calculation completed.\")\n",
    "    return final_zeta_spectrum, final_omega_spectrum\n",
    "\n",
    "\n",
    "logger.info(\"Starting zeta and omega computation for mix and spectra.\")\n",
    "zeta, omega = calculate_zeta_and_omega(\n",
    "    mix,\n",
    "    spectra,\n",
    "    kappa_mixture=kappa_mixture,\n",
    "    kappa_components=kappa_components,\n",
    ")\n",
    "logger.info(\"Zeta and omega computation finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta.plot(profile=False)\n",
    "omega.plot(profile=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magnetstein-8zJnuLRN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
