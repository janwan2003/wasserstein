{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from wasserstein import Spectrum, NMRSpectrum\n",
    "\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "components_names = [\"Pinene\", \"Benzyl benzoate\"]\n",
    "\n",
    "protons_list = [16, 12]\n",
    "\n",
    "filename = \"preprocessed_mix.csv\"\n",
    "mix = np.loadtxt(filename, delimiter=\",\")\n",
    "# If you are using file exported from Mnova, comment line above and uncomment line below.\n",
    "# mix = np.loadtxt(filename, delimiter='\\t', usecols=[0,1])\n",
    "\n",
    "how_many_components = len(components_names)\n",
    "names = [\"comp\" + str(i) for i in range(how_many_components)]\n",
    "\n",
    "files_with_components = [\"preprocessed_comp0.csv\", \"preprocessed_comp1.csv\"]\n",
    "spectra = []\n",
    "for i in range(how_many_components):\n",
    "    filename = files_with_components[i]\n",
    "    spectra.append(np.loadtxt(filename, delimiter=\",\"))\n",
    "    # If you are using file exported from Mnova, comment line above and uncomment line below.\n",
    "    # spectra.append(np.loadtxt(filename, delimiter='\\t', usecols=[0,1]))\n",
    "\n",
    "spectra2: List[NMRSpectrum] = []\n",
    "names = []\n",
    "for i in range(len(spectra)):\n",
    "    spectra2.append(\n",
    "        NMRSpectrum(\n",
    "            confs=list(zip(spectra[i][:, 0], spectra[i][:, 1])), protons=protons_list[i]\n",
    "        )\n",
    "    )\n",
    "    names.append(\"comp\" + str(i))\n",
    "\n",
    "spectra = spectra2\n",
    "del spectra2\n",
    "mix = NMRSpectrum(confs=list(zip(mix[:, 0], mix[:, 1])))\n",
    "mix.trim_negative_intensities()\n",
    "mix.normalize()\n",
    "for sp in spectra:\n",
    "    sp.trim_negative_intensities()\n",
    "    sp.normalize()\n",
    "plt.title(\"Mixture\")\n",
    "mix.plot(profile=True)\n",
    "for i, sp in enumerate(spectra):\n",
    "    plt.title(\"Component \" + str(i))\n",
    "    sp.plot(profile=True)\n",
    "print(spectra[0].confs[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   38.5  76.  113.5 151.  188.5 226.  263.5 301. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "linsapce = np.linspace(1, 301, 9)\n",
    "print(linsapce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_significant_features(first, second, n_features):\n",
    "    \"\"\"\n",
    "    Select the n most significant features from both spectra.\n",
    "    Uses combined intensity to determine importance.\n",
    "    \"\"\"\n",
    "    # Create dictionary with combined intensities\n",
    "    combined_intensities = {}\n",
    "    for mz, prob in first.confs:\n",
    "        combined_intensities[mz] = combined_intensities.get(mz, 0) + prob\n",
    "    for mz, prob in second.confs:\n",
    "        combined_intensities[mz] = combined_intensities.get(mz, 0) + prob\n",
    "\n",
    "    # Select top n features\n",
    "    selected_features = set(\n",
    "        sorted(\n",
    "            combined_intensities.keys(),\n",
    "            key=lambda mz: combined_intensities[mz],\n",
    "            reverse=True,\n",
    "        )[:n_features]\n",
    "    )\n",
    "\n",
    "    # Filter spectra\n",
    "    filtered_first = first.copy()\n",
    "    filtered_first.confs = [\n",
    "        (mz, prob) for mz, prob in first.confs if mz in selected_features\n",
    "    ]\n",
    "\n",
    "    filtered_second = second.copy()\n",
    "    filtered_second.confs = [\n",
    "        (mz, prob) for mz, prob in second.confs if mz in selected_features\n",
    "    ]\n",
    "\n",
    "    # Re-normalize\n",
    "    filtered_first.normalize()\n",
    "    filtered_second.normalize()\n",
    "\n",
    "    return filtered_first, filtered_second\n",
    "\n",
    "\n",
    "# Use only n most significant features\n",
    "spectra_damped = [None, None]\n",
    "spectra_damped[0], spectra_damped[1] = filter_significant_features(spectra[0], spectra[1], 2000)\n",
    "distance = spectra_damped[0].WSDistance(spectra_damped[1])\n",
    "# distance = WSDistance(spectra[0], spectra[1], n_features=2000)\n",
    "difference = spectra[0].WSDistance(spectra[1]) - distance\n",
    "print(distance)\n",
    "print(difference)\n",
    "\n",
    "gradient = spectra_damped[0].WSGradient(spectra_damped[1])\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "def calculate_gradient(mix, comp0, comp1, p, epsilon=1e-5):\n",
    "    delta = epsilon\n",
    "\n",
    "    p_plus = np.array([p[0] + delta, p[1] - delta])\n",
    "    p_minus = np.array([p[0] - delta, p[1] + delta])\n",
    "\n",
    "    p_plus = np.clip(p_plus, 1e-6, 1)\n",
    "    p_plus /= p_plus.sum()\n",
    "\n",
    "    p_minus = np.clip(p_minus, 1e-6, 1)\n",
    "    p_minus /= p_minus.sum()\n",
    "\n",
    "    sp_plus = Spectrum.ScalarProduct([comp0, comp1], p_plus)\n",
    "    sp_minus = Spectrum.ScalarProduct([comp0, comp1], p_minus)\n",
    "\n",
    "    sp_plus.normalize()\n",
    "    sp_minus.normalize()\n",
    "\n",
    "    grad = (mix.WSDistance(sp_plus) - mix.WSDistance(sp_minus)) / (2 * epsilon)\n",
    "\n",
    "    # Gradient of p[1] is -grad because p[1] = 1 - p[0]\n",
    "    grad_vec = np.array([grad, -grad])\n",
    "\n",
    "    return grad_vec\n",
    "\n",
    "\n",
    "def mirror_descent_two_weights(\n",
    "    mix, comp0, comp1, learning_rate=1.0, T=100, epsilon=1e-5\n",
    "):\n",
    "    p = np.array([0.5, 0.5])  # start from uniform mixture\n",
    "    history = [p.copy()]\n",
    "    scores = []\n",
    "\n",
    "    for _ in trange(T, desc=\"Mirror Descent (2 weights)\"):\n",
    "        # Track score (distance from current estimate to true mixture)\n",
    "        estimated_mix = Spectrum.ScalarProduct([comp0, comp1], p)\n",
    "        estimated_mix.normalize()\n",
    "        ws = mix.WSDistance(estimated_mix)\n",
    "        scores.append(ws)\n",
    "\n",
    "        # Compute gradient\n",
    "        grad_vec = calculate_gradient(mix, comp0, comp1, p, epsilon)\n",
    "\n",
    "        # Mirror descent update\n",
    "        w = p * np.exp(-learning_rate * grad_vec)\n",
    "        p = w / w.sum()\n",
    "\n",
    "        history.append(p.copy())\n",
    "\n",
    "    return p, np.array(history), np.array(scores)\n",
    "\n",
    "\n",
    "# Run mirror descent\n",
    "# mix.normalize()\n",
    "# spectra[0].normalize()\n",
    "# spectra[1].normalize()\n",
    "\n",
    "final_p, traj, score_history = mirror_descent_two_weights(\n",
    "    mix, spectra[0], spectra[1], learning_rate=0.0002, T=100\n",
    ")\n",
    "\n",
    "# Reconstruct mixture from estimated weights\n",
    "estimated_mix = Spectrum.ScalarProduct([spectra[0], spectra[1]], final_p)\n",
    "estimated_mix.normalize()\n",
    "\n",
    "# Compute Wasserstein distance to the actual mixture\n",
    "ws_dist = mix.WSDistance(estimated_mix)\n",
    "\n",
    "# Compute Wasserstein distance for the given mixture\n",
    "given_p = np.array([0.393072, 0.606928])\n",
    "given_mix = Spectrum.ScalarProduct([spectra[0], spectra[1]], given_p)\n",
    "given_mix.normalize()\n",
    "ws_dist_given = mix.WSDistance(given_mix)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal weights:\")\n",
    "print(f\"  comp1 = {final_p[0]:.4f}\")\n",
    "print(f\"  comp2 = {final_p[1]:.4f}\")\n",
    "print(f\"\\nFinal Wasserstein distance to true mixture: {ws_dist:.6f}\")\n",
    "print(\n",
    "    f\"\\nWasserstein distance for given mixture (0.393072, 0.606928): {ws_dist_given:.6f}\"\n",
    ")\n",
    "\n",
    "plt.plot(traj[:, 0], label=\"Component 0\")\n",
    "plt.plot(traj[:, 1], label=\"Component 1\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.title(\"Mirror Descent Weight Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(score_history, marker=\"o\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wasserstein Distance\")\n",
    "plt.title(\"Distance to True Mixture Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def numpy_to_torch_tensor(pairs):\n",
    "    return {\n",
    "        \"values\": torch.tensor([float(v) for v, _ in pairs], dtype=torch.float64, requires_grad=True),\n",
    "        \"probs\": torch.tensor([float(p) for _, p in pairs], dtype=torch.float64, requires_grad=True)\n",
    "    }\n",
    "\n",
    "spectra_torch = [numpy_to_torch_tensor(sp.confs) for sp in spectra]\n",
    "mix_torch = numpy_to_torch_tensor(mix.confs)\n",
    "\n",
    "print(spectra_torch[0][\"probs\"][:10])\n",
    "print(spectra_torch[0][\"values\"][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile_torch(spectre, quantiles):\n",
    "    # assume data normalized\n",
    "    values, probs = spectre[\"values\"], spectre[\"probs\"]\n",
    "    \n",
    "    sorted_indices = torch.argsort(values)\n",
    "    values = values[sorted_indices]\n",
    "    probs = probs[sorted_indices]\n",
    "    \n",
    "    cum_probs = torch.cumsum(probs, dim=0)\n",
    "\n",
    "    indices = torch.searchsorted(cum_probs, quantiles, right=True)\n",
    "    indices = torch.clamp(indices, 0, len(values) - 1)\n",
    "    quantile_values = values[indices]\n",
    "    \n",
    "    return quantile_values\n",
    "\n",
    "data = spectra_torch[0]\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "quantiles = torch.tensor(quantiles, dtype=torch.float64)\n",
    "result = weighted_quantile_torch(data, quantiles)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_distance(mu, nu, p=1):\n",
    "    _, mu_probs = mu[\"values\"], mu[\"probs\"]\n",
    "    _, nu_probs = nu[\"values\"], nu[\"probs\"]\n",
    "\n",
    "    cum_probs_mu = torch.cumsum(mu_probs, dim=0)\n",
    "    cum_probs_nu = torch.cumsum(nu_probs, dim=0)\n",
    "    \n",
    "    t = torch.cat([cum_probs_mu, cum_probs_nu])\n",
    "    t, _ = torch.sort(t)\n",
    "    \n",
    "    F_mu_inv = weighted_quantile_torch(mu, t)\n",
    "    F_nu_inv = weighted_quantile_torch(nu, t)\n",
    "    \n",
    "    integral = torch.trapz(torch.abs(F_mu_inv - F_nu_inv) ** p, t)\n",
    "    return integral ** (1 / p)\n",
    "\n",
    "\n",
    "ws = wasserstein_distance(spectra_torch[0], spectra_torch[1])\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_two_mix(p):\n",
    "    mu_values, mu_probs = spectra_torch[0][\"values\"], spectra_torch[0][\"probs\"]\n",
    "    nu_values, nu_probs = spectra_torch[1][\"values\"], spectra_torch[1][\"probs\"]\n",
    "    \n",
    "    estimated_values = mu_values * p[0] + nu_values * p[1]\n",
    "    estimated_probs = mu_probs * p[0] + nu_probs * p[1]\n",
    "    estimated_probs /= estimated_probs.sum()\n",
    "    \n",
    "    estimated_mix = {\n",
    "        \"values\": estimated_values,\n",
    "        \"probs\": estimated_probs\n",
    "    }\n",
    "    ws = wasserstein_distance(mix_torch, estimated_mix)\n",
    "    return ws\n",
    "\n",
    "p = torch.tensor([0.5, 0.5], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "ws = ws_two_mix(p)\n",
    "ws.backward()\n",
    "print(ws)\n",
    "print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_descent_torch(learning_rate=1.0, T=100):\n",
    "    p = torch.tensor([0.5, 0.5], dtype=torch.float64, requires_grad=True)\n",
    "    history = [p.clone().detach()]\n",
    "    scores = []\n",
    "\n",
    "    for _ in trange(T, desc=\"Mirror Descent (2 weights)\"):\n",
    "        ws = ws_two_mix(p)\n",
    "        ws.backward()\n",
    "        scores.append(ws.item())\n",
    "\n",
    "        # Mirror descent update\n",
    "        with torch.no_grad():\n",
    "            w = p * torch.exp(-learning_rate * p.grad)\n",
    "            p.copy_(w / w.sum())\n",
    "\n",
    "        p.grad.zero_()  # Reset gradients\n",
    "        history.append(p.clone().detach())\n",
    "\n",
    "    return p, history, scores\n",
    "\n",
    "final_p, traj, score_history = mirror_descent_torch(learning_rate=0.001, T=100)\n",
    "\n",
    "# plot scores\n",
    "plt.plot(score_history, marker=\"o\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wasserstein Distance\")\n",
    "plt.title(\"Distance to True Mixture Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "\n",
    "N = 800\n",
    "\n",
    "def signif_features(spectrum, n_features):\n",
    "    spectrum_confs = sorted(spectrum.confs, key=lambda x: x[1], reverse=True)[:n_features]\n",
    "    spectrum_signif = NMRSpectrum(confs=spectrum_confs, protons=spectrum.protons)\n",
    "    spectrum_signif.normalize()\n",
    "    return spectrum_signif\n",
    "\n",
    "spectra_signif = [None] * 2\n",
    "spectra_signif[0] = signif_features(spectra[0], N)\n",
    "spectra_signif[1] = signif_features(spectra[1], N)\n",
    "mix_signif = signif_features(mix, 2*N)\n",
    "\n",
    "for i, sp in enumerate(spectra):\n",
    "    plt.title(\"Component \" + str(i))\n",
    "    sp.plot(profile=True)\n",
    "    plt.title(\"Component \" + str(i) + \" signif\")\n",
    "    spectra_signif[i].plot(profile=True)\n",
    "\n",
    "plt.title(\"Mixture\")\n",
    "mix.plot(profile=True)\n",
    "plt.title(\"Mixture signif\")\n",
    "mix_signif.plot(profile=True)\n",
    "\n",
    "given_p = np.array([0.5, 0.5])\n",
    "given_mix = Spectrum.ScalarProduct([spectra_signif[0], spectra_signif[1]], given_p)\n",
    "given_mix.normalize()\n",
    "plt.title(\"Mixed signif 50-50\")\n",
    "given_mix.plot()\n",
    "\n",
    "given_mix_full = Spectrum.ScalarProduct([spectra[0], spectra[1]], given_p)\n",
    "given_mix_full.normalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix(spectrum1, spectrum2):\n",
    "    vals1 = [val for val, _ in spectrum1.confs]\n",
    "    vals2 = [val for val, _ in spectrum2.confs]\n",
    "    \n",
    "    cost = np.zeros((len(vals1), len(vals2)))\n",
    "    # cost = np.full((len(vals1), len(vals2)), np.inf)\n",
    "\n",
    "    for i, v1 in enumerate(vals1):\n",
    "        for j, v2 in enumerate(vals2):\n",
    "            cost[i, j] = v1 - v2\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# print(cost_matrix(spectra_signif[0], spectra_signif[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def sparse_cost_matrix(spectrum1, spectrum2, threshold=None, block_size=1000):\n",
    "    vals1 = np.array([val for val, _ in spectrum1.confs])\n",
    "    vals2 = np.array([val for val, _ in spectrum2.confs])\n",
    "\n",
    "    n1, n2 = len(vals1), len(vals2)\n",
    "    data, rows, cols = [], [], []\n",
    "\n",
    "    for i_start in trange(0, n1, block_size):\n",
    "        i_end = min(i_start + block_size, n1)\n",
    "        v1_block = vals1[i_start:i_end]\n",
    "\n",
    "        for j_start in range(0, n2, block_size):\n",
    "            j_end = min(j_start + block_size, n2)\n",
    "            v2_block = vals2[j_start:j_end]\n",
    "\n",
    "            # Broadcasted block subtraction\n",
    "            block_diff = v1_block[:, None] - v2_block[None, :]\n",
    "\n",
    "            if threshold is not None:\n",
    "                mask = np.abs(block_diff) <= threshold\n",
    "            else:\n",
    "                mask = np.ones_like(block_diff, dtype=bool)\n",
    "\n",
    "            bi, bj = np.nonzero(mask)\n",
    "            data.append(block_diff[bi, bj])\n",
    "            rows.append(bi + i_start)\n",
    "            cols.append(bj + j_start)\n",
    "\n",
    "    # Concatenate all data\n",
    "    data = np.concatenate(data)\n",
    "    rows = np.concatenate(rows)\n",
    "    cols = np.concatenate(cols)\n",
    "\n",
    "    sparse_cost = coo_matrix((data, (rows, cols)), shape=(n1, n2)).tocsr()\n",
    "    return sparse_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.array([p for _, p in mix_signif.confs])\n",
    "b = np.array([p for _, p in given_mix.confs])\n",
    "M = cost_matrix(mix_signif, given_mix)\n",
    "\n",
    "G0, log = ot.unbalanced.lbfgsb_unbalanced(a, b, M, reg=0, reg_m=5, reg_div='kl', regm_div='tv', log=True)\n",
    "print(log[\"res\"], log[\"cost\"], log[\"total_cost\"])\n",
    "# print(ot.unbalanced.lbfgsb_unbalanced2(a, b, M, reg=5, reg_m=5, reg_div='kl', regm_div='kl'))\n",
    "# print(ot.unbalanced.lbfgsb_unbalanced2(a, b, M, reg=5, reg_m=5, reg_div='l2', regm_div='tv'))\n",
    "# print(ot.unbalanced.lbfgsb_unbalanced2(a, b, M, reg=5, reg_m=5, reg_div='kl', regm_div='tv'))\n",
    "print(mix_signif.WSDistance(given_mix))\n",
    "\n",
    "\n",
    "# a2 = np.array([p for _, p in mix.confs])\n",
    "# b2 = np.array([p for _, p in given_mix_full.confs])\n",
    "# M_sparse = sparse_cost_matrix(mix, given_mix_full, threshold=0.01)\n",
    "# M2 = M_sparse.toarray()\n",
    "# print(M2.shape)\n",
    "# print(ot.unbalanced.lbfgsb_unbalanced2(a2, b2, M2, reg=0, reg_m=5, reg_div='kl', regm_div='tv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "def calculate_gradient_ot(mix, comp0, comp1, p, G0=None, epsilon=1e-5):\n",
    "    delta = epsilon\n",
    "\n",
    "    p_plus = np.array([p[0] + delta, p[1] - delta])\n",
    "    p_minus = np.array([p[0] - delta, p[1] + delta])\n",
    "\n",
    "    p_plus = np.clip(p_plus, 1e-6, 1)\n",
    "    p_plus /= p_plus.sum()\n",
    "\n",
    "    p_minus = np.clip(p_minus, 1e-6, 1)\n",
    "    p_minus /= p_minus.sum()\n",
    "\n",
    "    sp_plus = Spectrum.ScalarProduct([comp0, comp1], p_plus)\n",
    "    sp_minus = Spectrum.ScalarProduct([comp0, comp1], p_minus)\n",
    "\n",
    "    sp_plus.normalize()\n",
    "    sp_minus.normalize()\n",
    "\n",
    "    # grad = (mix.WSDistance(sp_plus) - mix.WSDistance(sp_minus)) / (2 * epsilon)\n",
    "\n",
    "    a = np.array([p for _, p in mix.confs])\n",
    "    b1 = np.array([p for _, p in sp_plus.confs])\n",
    "    b2 = np.array([p for _, p in sp_minus.confs])\n",
    "    M1 = cost_matrix(mix, sp_plus)\n",
    "    M2 = cost_matrix(mix, sp_minus)\n",
    "\n",
    "    ws_plus = ot.unbalanced.lbfgsb_unbalanced2(a, b1, M1, reg=0, reg_m=5, reg_div='kl', regm_div='tv')\n",
    "    ws_minus = ot.unbalanced.lbfgsb_unbalanced2(a, b2, M2, reg=0, reg_m=5, reg_div='kl', regm_div='tv')\n",
    "\n",
    "    grad = (ws_plus - ws_minus) / (2 * epsilon)\n",
    "    # Gradient of p[1] is -grad because p[1] = 1 - p[0]\n",
    "    grad_vec = np.array([grad, -grad])\n",
    "\n",
    "    return grad_vec\n",
    "\n",
    "\n",
    "def mirror_descent_ot(\n",
    "    mix, comp0, comp1, learning_rate=1.0, T=100, epsilon=1e-5, gamma=0.98\n",
    "):\n",
    "    p = np.array([0.5, 0.5])\n",
    "    history = [p.copy()]\n",
    "    scores = []\n",
    "    G0 = None\n",
    "\n",
    "    for _ in trange(T, desc=\"Mirror Descent (2 weights)\"):\n",
    "        estimated_mix = Spectrum.ScalarProduct([comp0, comp1], p)\n",
    "        estimated_mix.normalize()\n",
    "\n",
    "        a = np.array([p for _, p in mix.confs])\n",
    "        b = np.array([p for _, p in estimated_mix.confs])\n",
    "\n",
    "        M = cost_matrix(mix, estimated_mix)\n",
    "\n",
    "        G0, log = ot.unbalanced.lbfgsb_unbalanced(a, b, M, reg=0, reg_m=5, reg_div='kl', regm_div='tv', log=True)\n",
    "        ws = log[\"cost\"]\n",
    "        print(log[\"res\"][\"nit\"])\n",
    "        print(log[\"res\"][\"fun\"])\n",
    "        print(ws)\n",
    "        # ws = abs(ot.unbalanced.lbfgsb_unbalanced2(a, b, M, reg=0, reg_m=5, reg_div='kl', regm_div='tv'))\n",
    "        scores.append(ws)\n",
    "\n",
    "        grad_vec = calculate_gradient_ot(mix, comp0, comp1, p, epsilon)\n",
    "\n",
    "        w = p * np.exp(-learning_rate * grad_vec)\n",
    "        p = w / w.sum()\n",
    "\n",
    "        learning_rate *= gamma\n",
    "\n",
    "        history.append(p.copy())\n",
    "\n",
    "    return p, np.array(history), np.array(scores)\n",
    "\n",
    "final_p, traj, score_history = mirror_descent_ot(\n",
    "    mix_signif, spectra_signif[0], spectra_signif[1], learning_rate=0.02, T=40, gamma=0.98\n",
    ")\n",
    "\n",
    "print(\"\\nFinal weights:\")\n",
    "print(f\"  comp1 = {final_p[0]:.4f}\")\n",
    "print(f\"  comp2 = {final_p[1]:.4f}\")\n",
    "\n",
    "plt.plot(traj[:, 0], label=\"Component 0\")\n",
    "plt.plot(traj[:, 1], label=\"Component 1\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.title(\"Mirror Descent Weight Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(score_history, marker=\"o\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wasserstein Distance\")\n",
    "plt.title(\"Distance to True Mixture Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([p for _, p in mix_signif.confs])\n",
    "b = np.array([p for _, p in given_mix.confs])\n",
    "M = cost_matrix(mix_signif, given_mix)\n",
    "\n",
    "G0 = a[:, None] * b[None, :]\n",
    "\n",
    "ws1 = np.sum(G0 * M)\n",
    "ws2 = (mix_signif.WSDistance(given_mix))\n",
    "\n",
    "print(ws1, ws2)\n",
    "\n",
    "def ws_naive(spectrum1, spectrum2, block_size=700):\n",
    "    vals1 = np.array([val for val, _ in spectrum1.confs])\n",
    "    a = np.array([p for _, p in spectrum1.confs])\n",
    "\n",
    "    vals2 = np.array([val for val, _ in spectrum2.confs])\n",
    "    b = np.array([p for _, p in spectrum2.confs])\n",
    "\n",
    "    ws = 0.0\n",
    "\n",
    "    for i_start in trange(0, len(vals1), block_size):\n",
    "        i_end = min(i_start + block_size, len(vals1))\n",
    "        v1_block = vals1[i_start:i_end]\n",
    "        a_block = a[i_start:i_end]\n",
    "\n",
    "        # Broadcasting cost difference and G0 incrementally\n",
    "        diff_block = v1_block[:, None] - vals2[None, :]\n",
    "        prob_block = a_block[:, None] * b[None, :]\n",
    "\n",
    "        ws += np.sum(prob_block * diff_block)\n",
    "\n",
    "    return ws\n",
    "\n",
    "def ws_direct(spectrum1, spectrum2):\n",
    "    vals1 = np.array([val for val, _ in spectrum1.confs])\n",
    "    a = np.array([p for _, p in spectrum1.confs])\n",
    "\n",
    "    vals2 = np.array([val for val, _ in spectrum2.confs])\n",
    "    b = np.array([p for _, p in spectrum2.confs])\n",
    "\n",
    "    # Normalize in case the inputs are not exact probabilities\n",
    "    a /= a.sum()\n",
    "    b /= b.sum()\n",
    "\n",
    "    return abs(np.dot(a, vals1) - np.dot(b, vals2))\n",
    "\n",
    "\n",
    "\n",
    "# ws1_full = ws_naive(mix, given_mix_full)\n",
    "ws2_full = mix.WSDistance(given_mix_full)\n",
    "ws1_full = ws_direct(mix, given_mix_full)\n",
    "\n",
    "print(len(mix.confs), len(given_mix_full.confs))\n",
    "print(ws1_full, ws2_full)\n",
    "\n",
    "\n",
    "# f(p) = ws_direct(mix, p*s1 + (1-p)*s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_naive(mix, comp0, comp1, p, epsilon=1e-5):\n",
    "    grad_vec = np.zeros_like(p)\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        # Create perturbed copies\n",
    "        p_plus = p.copy()\n",
    "        p_minus = p.copy()\n",
    "\n",
    "        p_plus[i] += epsilon\n",
    "        p_minus[i] -= epsilon\n",
    "\n",
    "        # Clip and renormalize\n",
    "        p_plus = np.clip(p_plus, 1e-6, 1)\n",
    "        p_plus /= p_plus.sum()\n",
    "\n",
    "        p_minus = np.clip(p_minus, 1e-6, 1)\n",
    "        p_minus /= p_minus.sum()\n",
    "\n",
    "        # Create mixed spectra\n",
    "        sp_plus = Spectrum.ScalarProduct([comp0, comp1], p_plus)\n",
    "        sp_minus = Spectrum.ScalarProduct([comp0, comp1], p_minus)\n",
    "\n",
    "        sp_plus.normalize()\n",
    "        sp_minus.normalize()\n",
    "\n",
    "        # Finite difference for the i-th coordinate\n",
    "        grad_vec[i] = (ws_direct(mix, sp_plus) - ws_direct(mix, sp_minus)) / (2 * epsilon)\n",
    "\n",
    "    return grad_vec\n",
    "\n",
    "\n",
    "def mirror_descent_naive(\n",
    "    mix, comp0, comp1, learning_rate=1.0, T=100, epsilon=1e-5, gamma=0.8\n",
    "):\n",
    "    p = np.array([0.5, 0.5])\n",
    "    history = [p.copy()]\n",
    "    scores = []\n",
    "\n",
    "    for _ in trange(T, desc=\"Mirror Descent (2 weights)\"):\n",
    "        estimated_mix = Spectrum.ScalarProduct([comp0, comp1], p)\n",
    "        estimated_mix.normalize()\n",
    "\n",
    "        scores.append(ws_direct(mix, estimated_mix))\n",
    "        grad_vec = calculate_gradient_naive(mix, comp0, comp1, p, epsilon)\n",
    "\n",
    "        w = p * np.exp(-learning_rate * grad_vec)\n",
    "        p = w / w.sum()\n",
    "\n",
    "        learning_rate *= gamma\n",
    "\n",
    "        history.append(p.copy())\n",
    "\n",
    "    return p, np.array(history), np.array(scores)\n",
    "\n",
    "final_p, traj, score_history = mirror_descent_naive(\n",
    "    mix, spectra[0], spectra[1], learning_rate=0.005, T=50, gamma=0.90\n",
    ")\n",
    "\n",
    "print(\"\\nFinal weights:\")\n",
    "print(f\"  comp1 = {final_p[0]:.4f}\")\n",
    "print(f\"  comp2 = {final_p[1]:.4f}\")\n",
    "\n",
    "plt.plot(traj[:, 0], label=\"Component 0\")\n",
    "plt.plot(traj[:, 1], label=\"Component 1\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.title(\"Mirror Descent Weight Evolution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(score_history, marker=\"o\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wasserstein Distance\")\n",
    "plt.title(\"Distance to True Mixture Over Iterations\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_cost_matrix(spectrum1, spectrum2, threshhold=5.0):\n",
    "    vals1 = [val for val, _ in spectrum1.confs]\n",
    "    vals2 = [val for val, _ in spectrum2.confs]\n",
    "    \n",
    "    # cost = np.full((len(vals1), len(vals2)), 0)\n",
    "    cost = np.zeros((len(vals1), len(vals2)))\n",
    "    \n",
    "    for i, v1 in enumerate(vals1):\n",
    "        for j, v2 in enumerate(vals2):\n",
    "            # if abs(v1 - v2) <= threshhold:\n",
    "            cost[i, j] = v1 - v2\n",
    "    \n",
    "    return cost\n",
    "\n",
    "TEST_N = 200\n",
    "\n",
    "# 0.011216905452141613\n",
    "# 0.010568778251053077\n",
    "\n",
    "true_p = np.array([0.5, 0.5])\n",
    "aprox_mix = Spectrum.ScalarProduct([signif_features(spectra[0], TEST_N), signif_features(spectra[1], TEST_N)], true_p)\n",
    "aprox_mix.normalize()\n",
    "mix_test = signif_features(mix, 2*TEST_N)\n",
    "\n",
    "p1 = np.array([p for _, p in mix_test.confs])\n",
    "v1 = np.array([v for v, _ in mix_test.confs])\n",
    "p2 = np.array([p for _, p in aprox_mix.confs])\n",
    "v2 = np.array([v for v, _ in aprox_mix.confs])\n",
    "M_test = true_cost_matrix(mix_test, aprox_mix)\n",
    "reg_m = np.array([0, 0])\n",
    "\n",
    "given_mix_full = Spectrum.ScalarProduct([spectra[0], spectra[1]], true_p)\n",
    "given_mix_full.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0, log = ot.unbalanced.lbfgsb_unbalanced(p1, p2, M_test, reg=0, reg_m=reg_m, reg_div='kl', regm_div='tv', log=True, verbose=True, numItermax=1500)\n",
    "print(log[\"res\"])\n",
    "print(log[\"cost\"], log[\"total_cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mix_test.WSDistance(aprox_mix))\n",
    "print(mix.WSDistance(given_mix_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "print(wasserstein_distance(v1, v2, p1, p2))\n",
    "\n",
    "p1_full = np.array([p for _, p in mix.confs])\n",
    "v1_full = np.array([v for v, _ in mix.confs])\n",
    "p2_full = np.array([p for _, p in given_mix_full.confs])\n",
    "v2_full = np.array([v for v, _ in given_mix_full.confs])\n",
    "\n",
    "print(wasserstein_distance(p1_full, p2_full, v1_full, v2_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = p1[:, None] * p2[None, :]\n",
    "\n",
    "print(np.sum(G0 * M_test)) # E_p1(v1) - E_p2(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ot.emd2(p1, p2, M_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wasserstein-ZSZ5D0L9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
